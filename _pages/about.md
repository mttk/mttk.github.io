---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a postdoc at [TakeLab](https://takelab.fer.hr/), University of Zagreb. My research interests within natural language processing are faithful explainability, safety and controllability of language models.

Previously, I did a postdoc at the Technion working with [Yonatan Belinkov](https://belinkov.com/) working on unlearning and faithful explainability of language models. Before that, I did a postdoc at the [UKP Lab](https://www.informatik.tu-darmstadt.de/ukp/ukp_home/index.en.jsp) at TU Darmstadt working with [Iryna Gurevych](https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp) on the [InterText](https://intertext.ukp-lab.de/) initiative. I obtained my PhD at the University of Zagreb under supervision of [Jan Å najder](http://www.zemris.fer.hr/~jan/). Before my PhD I worked at the European Commission's [Joint Research Centre](https://commission.europa.eu/about-european-commission/departments-and-executive-agencies/joint-research-centre_en) in Ispra on using NLP to update the the [Sendai Framework for Disaster Risk Reduction 2015-2030](https://www.undrr.org/publication/sendai-framework-disaster-risk-reduction-2015-2030).

I am on the job market for academic opportunities. Check my [CV](https://mttk.github.io/files/CV_Tutek_Martin_Aug_2025.pdf) and [reach out](https://mttk.github.io/contact/) if you believe me a good fit.

News
======
**October 2025.**
- We released a benchmark evaluating whether LLM agents are safe for use in managerial decisions. Check out the [[paper & data]](https://technion-cs-nlp.github.io/ManagerBench-website/)!

**September 2025.**
- We released a new preprint on directly encoding contextual information into adapter parameters in a compositional manner! Check out the [[paper]](https://arxiv.org/abs/2509.22158)

**August 2025.**
- FUR was accepted as an oral at [EMNLP 2025](https://2025.emnlp.org/) main, and (non-archival) at the [Interplay workshop](https://interplay-workshop.github.io/) at COLM 2025! Check out the [[paper]](https://arxiv.org/abs/2502.14829).
- We released a new preprint on using SAEs to precisely & permanently erase harmful concepts from LMs! Check out the preprint: [[paper]](https://arxiv.org/abs/2508.13650).

**July 2025.**
- Two papers will be presented at the [Interplay workshop](https://interplay-workshop.github.io/) at COLM 2025: FUR as non-archival [[paper]](https://arxiv.org/abs/2502.14829), and [Predicting Success of Model Editing via Intrinsic Features](https://openreview.net/pdf?id=qQNiXK0U0J) as archival!

**June 2025.**
- Our paper studying diachronic word embeddings trained on Croatian has been accepted to the [Slavic NLP workshop](https://bsnlp.cs.helsinki.fi/index.html) at ACL 2025! Check out our [[paper]](https://arxiv.org/abs/2506.13569).

**May 2025.**
- REVS, our gradient-free method for erasing sensitive information from language models has been accepted to the [Findings of ACL 2025](https://2025.aclweb.org/)! Check out the [[paper & code]](https://technion-cs-nlp.github.io/REVS/).

**April 2025.**
- We released [a Mechanistic Interpretability Benchmark](https://mib-bench.github.io/), a step towards standardizing evaluation in mechanistic interpretability! The paper describing our effort has been accepted to [ICML 2025](https://icml.cc/).

**September 2024.**
- Our paper on prompting models with pseudocode to improve their conditional reasoning capabilities is accepted to [EMNLP 2024](https://2024.emnlp.org/) main! Check out the [[paper]](https://arxiv.org/abs/2401.10065) 
